### 🏗️ Stage 2: 구조설계 및 제약 분석

Stage 1의 목표(속도 A)와 사용자가 제시한 현실 제약(관리 최소화) 사이의 충돌을 분석하고 해결책을 마련했습니다.

#### Part 1. 외부 제약 및 충돌 분석 (`02C-02`)

가장 큰 기술적 도전 과제는 **"실시간성(속도 A)"**과 **"외부 API 의존"** 간의 충돌입니다.

**💥 충돌: 속도(A) vs 외부 API 지연 (Google STT + Gemini)**

- **목표**: 사용자 발언 후 1초 이내 반응 (NFR: 속도 A)
- **제약**:
  - Google STT 스트리밍 인식은 빠르지만 네트워크 홉(Hop)이 존재합니다.
  - Gemini API는 LLM 특성상 토큰 생성에 시간이 걸립니다 (수 초 소요 가능).
  - Python은 동기적으로 처리하면 다른 사용자의 요청을 막을 수 있습니다 (GIL 이슈).

**🛠️ 해결 전략 (Trade-off 결정)**

1. **비동기 스트리밍 (Async Streaming)**: FastAPI의 `async/await`를 적극 활용하여, STT 결과를 기다리는 동안에도 다른 I/O를 차단하지 않도록 합니다. 2
2. **낙관적 UI (Optimistic UI)**: STT 결과가 확정되기 전, '인식 중인 텍스트(Interim result)'를 먼저 클라이언트에 뿌려주어 체감 지연을 없앱니다.
3. **스트리밍 응답**: Gemini의 답변을 다 기다리지 않고, 생성되는 토큰 단위로 즉시 전송(Streaming Response)합니다.

------

#### Part 2. 기술 스택 최종 확정 (`02D-01`)

"인프라 관리 최소화"와 "빠른 개발"을 최우선으로 하여 빈칸을 채웠습니다.

| **구분**            | **확정 기술**                         | **선택 근거**                                                |
| ------------------- | ------------------------------------- | ------------------------------------------------------------ |
| **언어/프레임워크** | **Python 3.12 + FastAPI**             | AI 통합 용이, 개발 속도 빠름, 비동기 지원 우수 3333          |
| **실시간 통신**     | **Native WebSocket**                  | FastAPI 내장 기능 활용. 별도 라이브러리(Socket.io) 없이 가볍게 구현하여 오버헤드 최소화 4444 |
| **STT (음성인식)**  | **Google Cloud STT**                  | 관리형 서비스. 한국어 인식률 우수, 실시간 스트리밍 API 지원  |
| **AI (두뇌)**       | **Gemini 1.5 Flash**                  | 대회용으로 최적. 속도가 빠르고 비용 효율적이며 긴 컨텍스트 처리에 유리 |
| **DB (저장소)**     | **SQLite (개발) → PostgreSQL (운영)** | 초기엔 파일 기반 SQLite로 설정 없이 개발하고, 배포 시 Docker 컨테이너 하나로 PostgreSQL 전환 (ORM 사용으로 코드 수정 불필요) 5 |
| **Cache/Queue**     | **Python 내장 `asyncio.Queue`**       | Redis 등 별도 인프라를 띄우지 않고, Python 메모리 큐를 사용하여 인프라 제로화 (단일 서버 기준) |

------





# 기술 스택 결정: AI Moderator

## 핵심 결정
- **Backend**: Python FastAPI (비동기 처리 최적화)
- **AI/ML**: Google Cloud STT + Gemini API (관리형 서비스로 인프라 부담 제거)
- **Infrastructure**: 단일 서버 아키텍처 (복잡한 분산 시스템 배제)

## 제약 사항 반영
- **대회 기간**: Redis, Kafka 등 추가 인프라 도입을 배제하고 Python 내장 기능(Memory Queue)으로 대체하여 설정 시간을 단축함.
- **성능 목표**: WebSocket과 LLM 스트리밍을 통해 체감 지연시간 < 1초 달성 목표.